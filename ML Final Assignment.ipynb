{
    "cells": [
        {
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "cell_type": "markdown",
            "source": "Lets first load required libraries:"
        },
        {
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "cell_type": "code",
            "source": "import itertools\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import NullFormatter\nimport pandas as pd\nimport numpy as np\nimport matplotlib.ticker as ticker\nfrom sklearn import preprocessing\n%matplotlib inline",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "cell_type": "markdown",
            "source": "### About dataset"
        },
        {
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "cell_type": "markdown",
            "source": "This dataset is about past loans. The __Loan_train.csv__ data set includes details of 346 customers whose loan are already paid off or defaulted. It includes following fields:\n\n| Field          | Description                                                                           |\n|----------------|---------------------------------------------------------------------------------------|\n| Loan_status    | Whether a loan is paid off on in collection                                           |\n| Principal      | Basic principal loan amount at the                                                    |\n| Terms          | Origination terms which can be weekly (7 days), biweekly, and monthly payoff schedule |\n| Effective_date | When the loan got originated and took effects                                         |\n| Due_date       | Since it\u2019s one-time payoff schedule, each loan has one single due date                |\n| Age            | Age of applicant                                                                      |\n| Education      | Education of applicant                                                                |\n| Gender         | The gender of applicant                                                               |"
        },
        {
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "cell_type": "markdown",
            "source": "Lets download the dataset"
        },
        {
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "cell_type": "code",
            "source": "!wget -O loan_train.csv https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/loan_train.csv",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "cell_type": "markdown",
            "source": "### Load Data From CSV File  "
        },
        {
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "cell_type": "code",
            "source": "df = pd.read_csv('loan_train.csv')\ndf.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df.shape",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "cell_type": "markdown",
            "source": "### Convert to date time object "
        },
        {
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "cell_type": "code",
            "source": "df['due_date'] = pd.to_datetime(df['due_date'])\ndf['effective_date'] = pd.to_datetime(df['effective_date'])\ndf.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "cell_type": "markdown",
            "source": "# Data visualization and pre-processing\n\n"
        },
        {
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "cell_type": "markdown",
            "source": "Let\u2019s see how many of each class is in our data set "
        },
        {
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "cell_type": "code",
            "source": "df['loan_status'].value_counts()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "cell_type": "markdown",
            "source": "260 people have paid off the loan on time while 86 have gone into collection \n"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Lets plot some columns to underestand data better:"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# notice: installing seaborn might takes a few minutes\n!conda install -c anaconda seaborn -y",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "import seaborn as sns\n\nbins = np.linspace(df.Principal.min(), df.Principal.max(), 10)\ng = sns.FacetGrid(df, col=\"Gender\", hue=\"loan_status\", palette=\"Set1\", col_wrap=2)\ng.map(plt.hist, 'Principal', bins=bins, ec=\"k\")\n\ng.axes[-1].legend()\nplt.show()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "cell_type": "code",
            "source": "bins = np.linspace(df.age.min(), df.age.max(), 10)\ng = sns.FacetGrid(df, col=\"Gender\", hue=\"loan_status\", palette=\"Set1\", col_wrap=2)\ng.map(plt.hist, 'age', bins=bins, ec=\"k\")\n\ng.axes[-1].legend()\nplt.show()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "cell_type": "markdown",
            "source": "# Pre-processing:  Feature selection/extraction"
        },
        {
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "cell_type": "markdown",
            "source": "### Lets look at the day of the week people get the loan "
        },
        {
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "cell_type": "code",
            "source": "df['dayofweek'] = df['effective_date'].dt.dayofweek\nbins = np.linspace(df.dayofweek.min(), df.dayofweek.max(), 10)\ng = sns.FacetGrid(df, col=\"Gender\", hue=\"loan_status\", palette=\"Set1\", col_wrap=2)\ng.map(plt.hist, 'dayofweek', bins=bins, ec=\"k\")\ng.axes[-1].legend()\nplt.show()\n",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "cell_type": "markdown",
            "source": "We see that people who get the loan at the end of the week dont pay it off, so lets use Feature binarization to set a threshold values less then day 4 "
        },
        {
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "cell_type": "code",
            "source": "df['weekend'] = df['dayofweek'].apply(lambda x: 1 if (x>3)  else 0)\ndf.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "cell_type": "markdown",
            "source": "## Convert Categorical features to numerical values"
        },
        {
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "cell_type": "markdown",
            "source": "Lets look at gender:"
        },
        {
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "cell_type": "code",
            "source": "df.groupby(['Gender'])['loan_status'].value_counts(normalize=True)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "cell_type": "markdown",
            "source": "86 % of female pay there loans while only 73 % of males pay there loan\n"
        },
        {
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "cell_type": "markdown",
            "source": "Lets convert male to 0 and female to 1:\n"
        },
        {
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "cell_type": "code",
            "source": "df['Gender'].replace(to_replace=['male','female'], value=[0,1],inplace=True)\ndf.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "cell_type": "markdown",
            "source": "## One Hot Encoding  \n#### How about education?"
        },
        {
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "cell_type": "code",
            "source": "df.groupby(['education'])['loan_status'].value_counts(normalize=True)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "cell_type": "markdown",
            "source": "#### Feature befor One Hot Encoding"
        },
        {
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "cell_type": "code",
            "source": "df[['Principal','terms','age','Gender','education']].head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "cell_type": "markdown",
            "source": "#### Use one hot encoding technique to conver categorical varables to binary variables and append them to the feature Data Frame "
        },
        {
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "cell_type": "code",
            "source": "Feature = df[['Principal','terms','age','Gender','weekend']]\nFeature = pd.concat([Feature,pd.get_dummies(df['education'])], axis=1)\nFeature.drop(['Master or Above'], axis = 1,inplace=True)\nFeature.head()\n",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "cell_type": "markdown",
            "source": "### Feature selection"
        },
        {
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "cell_type": "markdown",
            "source": "Lets defind feature sets, X:"
        },
        {
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "cell_type": "code",
            "source": "X = Feature\nX[0:5]",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "cell_type": "markdown",
            "source": "What are our lables?"
        },
        {
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "cell_type": "code",
            "source": "y = df['loan_status'].values\ny[0:5]",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "cell_type": "markdown",
            "source": "## Normalize Data "
        },
        {
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "cell_type": "markdown",
            "source": "Data Standardization give data zero mean and unit variance (technically should be done after train test split )"
        },
        {
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "cell_type": "code",
            "source": "X= preprocessing.StandardScaler().fit(X).transform(X)\nX[0:5]",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "cell_type": "markdown",
            "source": "# Classification "
        },
        {
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "cell_type": "markdown",
            "source": "Now, it is your turn, use the training set to build an accurate model. Then use the test set to report the accuracy of the model\nYou should use the following algorithm:\n- K Nearest Neighbor(KNN)\n- Decision Tree\n- Support Vector Machine\n- Logistic Regression\n\n\n\n__ Notice:__ \n- You can go above and change the pre-processing, feature selection, feature-extraction, and so on, to make a better model.\n- You should use either scikit-learn, Scipy or Numpy libraries for developing the classification algorithms.\n- You should include the code of the algorithm in the following cells."
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## Train Test split"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=4)\nprint ('Train set:', x_train.shape,  y_train.shape)\nprint ('Test set:', x_test.shape,  y_test.shape)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# K Nearest Neighbor(KNN)\nNotice: You should find the best k to build the model with the best accuracy.  \n**warning:** You should not use the __loan_test.csv__ for finding the best k, however, you can split your train_loan.csv into train and test to find the best __k__."
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### Importing libraries"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### Checking for the best value of K"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "for k in range(1, 10):\n    knn_model  = KNeighborsClassifier(n_neighbors = k).fit(x_train, y_train)\n    knn_yhat = knn_model.predict(x_test)\n    print(\"For K = {} accuracy = {}\".format(k,accuracy_score(y_test,knn_yhat)))",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "print(\"We can see that the KNN model is the best for K=7\")",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### Building the model with the best value of K = 7"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "best_knn_model = KNeighborsClassifier(n_neighbors = 7).fit(x_train, y_train)\nbest_knn_model",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "## Evaluation Metrics\n# jaccard score and f1 score\nfrom sklearn.metrics import jaccard_similarity_score\nfrom sklearn.metrics import f1_score\n\nprint(\"Train set Accuracy (Jaccard): \", jaccard_similarity_score(y_train, best_knn_model.predict(x_train)))\nprint(\"Test set Accuracy (Jaccard): \", jaccard_similarity_score(y_test, best_knn_model.predict(x_test)))\n\nprint(\"Train set Accuracy (F1): \", f1_score(y_train, best_knn_model.predict(x_train), average='weighted'))\nprint(\"Test set Accuracy (F1): \", f1_score(y_test, best_knn_model.predict(x_test), average='weighted'))",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# Decision Tree"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# importing libraries\nfrom sklearn.tree import DecisionTreeClassifier",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "for d in range(1,10):\n    dt = DecisionTreeClassifier(criterion = 'entropy', max_depth = d).fit(x_train, y_train)\n    dt_yhat = dt.predict(x_test)\n    print(\"For depth = {}  the accuracy score is {} \".format(d, accuracy_score(y_test, dt_yhat)))",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "print(\"The best value of depth is d = 2 \")",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "## Creating the best model for decision tree with best value of depth 2\n\nbest_dt_model = DecisionTreeClassifier(criterion = 'entropy', max_depth = 2).fit(x_train, y_train)\nbest_dt_model",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "## Evaluation Metrics\n# jaccard score and f1 score\nfrom sklearn.metrics import jaccard_similarity_score\nfrom sklearn.metrics import f1_score\n\nprint(\"Train set Accuracy (Jaccard): \", jaccard_similarity_score(y_train, best_dt_model.predict(x_train)))\nprint(\"Test set Accuracy (Jaccard): \", jaccard_similarity_score(y_test, best_dt_model.predict(x_test)))\n\nprint(\"Train set Accuracy (F1): \", f1_score(y_train, best_dt_model.predict(x_train), average='weighted'))\nprint(\"Test set Accuracy (F1): \", f1_score(y_test, best_dt_model.predict(x_test), average='weighted'))",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# Support Vector Machine"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#importing svm\nfrom sklearn import svm \nfrom sklearn.metrics import f1_score",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "for k in ('linear', 'poly', 'rbf','sigmoid'):\n    svm_model = svm.SVC( kernel = k).fit(x_train,y_train)\n    svm_yhat = svm_model.predict(x_test)\n    print(\"For kernel: {}, the f1 score is: {}\".format(k,f1_score(y_test,svm_yhat, average='weighted')))",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "print(\"We can see the rbf has the best f1 score \")",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "## building best SVM with kernel = rbf\nbest_svm = svm.SVC(kernel='rbf').fit(x_train,y_train)\nbest_svm",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "## Evaluation Metrics\n# jaccard score and f1 score\nfrom sklearn.metrics import jaccard_similarity_score\nfrom sklearn.metrics import f1_score\n\nprint(\"Train set Accuracy (Jaccard): \", jaccard_similarity_score(y_train, best_svm.predict(x_train)))\nprint(\"Test set Accuracy (Jaccard): \", jaccard_similarity_score(y_test, best_svm.predict(x_test)))\n\nprint(\"Train set Accuracy (F1): \", f1_score(y_train, best_svm.predict(x_train), average='weighted'))\nprint(\"Test set Accuracy (F1): \", f1_score(y_test, best_svm.predict(x_test), average='weighted'))",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# Logistic Regression"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# importing libraries\nfrom sklearn.linear_model import LogisticRegression \nfrom sklearn.metrics import log_loss",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "for k in ('lbfgs', 'saga', 'liblinear', 'newton-cg', 'sag'):\n    lr_model = LogisticRegression(C = 0.01, solver = k).fit(x_train, y_train)\n    lr_yhat = lr_model.predict(x_test)\n    y_prob = lr_model.predict_proba(x_test)\n    print('When Solver is {}, logloss is : {}'.format(k, log_loss(y_test, y_prob)))",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "print(\"We can see that the best solver is liblinear\")",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Best logistic regression model with liblinear solver\n\nbest_lr_model = LogisticRegression(C = 0.01, solver = 'liblinear').fit(x_train, y_train)\nbest_lr_model",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "## Evaluation Metrics\n# jaccard score and f1 score\nfrom sklearn.metrics import jaccard_similarity_score\nfrom sklearn.metrics import f1_score\n\nprint(\"Train set Accuracy (Jaccard): \", jaccard_similarity_score(y_train, best_lr_model.predict(x_train)))\nprint(\"Test set Accuracy (Jaccard): \", jaccard_similarity_score(y_test, best_lr_model.predict(x_test)))\n\nprint(\"Train set Accuracy (F1): \", f1_score(y_train, best_lr_model.predict(x_train), average='weighted'))\nprint(\"Test set Accuracy (F1): \", f1_score(y_test, best_lr_model.predict(x_test), average='weighted'))",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# Model Evaluation using Test set"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from sklearn.metrics import jaccard_similarity_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import log_loss",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "First, download and load the test set:"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "!wget -O loan_test.csv https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/loan_test.csv",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "cell_type": "markdown",
            "source": "### Load Test set for evaluation "
        },
        {
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "cell_type": "code",
            "source": "test_df = pd.read_csv('loan_test.csv')\ntest_df.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# data processing\ntest_df['due_date'] = pd.to_datetime(test_df['due_date'])\ntest_df['effective_date'] = pd.to_datetime(test_df['effective_date'])\ntest_df['dayofweek'] = test_df['effective_date'].dt.dayofweek\n\ntest_df['weekend'] = test_df['dayofweek'].apply(lambda x: 1 if (x>3)  else 0)\ntest_df['Gender'].replace(to_replace=['male','female'], value=[0,1],inplace=True)\n\nFeature1 = test_df[['Principal','terms','age','Gender','weekend']]\nFeature1 = pd.concat([Feature1,pd.get_dummies(test_df['education'])], axis=1)\nFeature1.drop(['Master or Above'], axis = 1,inplace=True)\n\n\nx_loan_test = Feature1\nx_loan_test = preprocessing.StandardScaler().fit(x_loan_test).transform(x_loan_test)\n\ny_loan_test = test_df['loan_status'].values",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Jaccard\n\n# KNN\nknn_yhat = best_knn_model.predict(x_loan_test)\njacc1 = round(jaccard_similarity_score(y_loan_test, knn_yhat), 2)\n\n# Decision Tree\ndt_yhat = best_dt_model.predict(x_loan_test)\njacc2 = round(jaccard_similarity_score(y_loan_test, dt_yhat), 2)\n\n# Support Vector Machine\nsvm_yhat = best_svm.predict(x_loan_test)\njacc3 = round(jaccard_similarity_score(y_loan_test, svm_yhat), 2)\n\n# Logistic Regression\nlr_yhat = best_lr_model.predict(x_loan_test)\njacc4 = round(jaccard_similarity_score(y_loan_test, lr_yhat), 2)\n\njss = [jacc1, jacc2, jacc3, jacc4]\njss",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# F1_score\n\n# KNN\nknn_yhat = best_knn_model.predict(x_loan_test)\nf1 = round(f1_score(y_loan_test, knn_yhat, average = 'weighted'), 2)\n\n# Decision Tree\ndt_yhat = best_dt_model.predict(x_loan_test)\nf2 = round(f1_score(y_loan_test, dt_yhat, average = 'weighted'), 2)\n\n# Support Vector Machine\nsvm_yhat = best_svm.predict(x_loan_test)\nf3 = round(f1_score(y_loan_test, svm_yhat, average = 'weighted'), 2)\n\n# Logistic Regression\nlr_yhat = best_lr_model.predict(x_loan_test)\nf4 = round(f1_score(y_loan_test, lr_yhat, average = 'weighted'), 2)\n\nf1_list = [f1, f2, f3, f4]\nf1_list",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# log loss\n\n# Logistic Regression\nlr_prob = best_lr_model.predict_proba(x_loan_test)\nll_list = ['NA','NA','NA', round(log_loss(y_loan_test, lr_prob), 2)]\nll_list",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "columns = ['KNN', 'Decision Tree', 'SVM', 'Logistic Regression']\nindex = ['Jaccard', 'F1-score', 'Logloss']\n\naccuracy_df = pd.DataFrame([jss, f1_list, ll_list], index = index, columns = columns)\naccuracy_df1 = accuracy_df.transpose()\naccuracy_df1.columns.name = 'Algorithm'\naccuracy_df1",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# Report\nYou should be able to report the accuracy of the built model using different evaluation metrics:"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "| Algorithm          | Jaccard | F1-score | LogLoss |\n|--------------------|---------|----------|---------|\n| KNN                | ?       | ?        | NA      |\n| Decision Tree      | ?       | ?        | NA      |\n| SVM                | ?       | ?        | NA      |\n| LogisticRegression | ?       | ?        | ?       |"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.7",
            "language": "python"
        },
        "language_info": {
            "name": "python",
            "version": "3.7.9",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}